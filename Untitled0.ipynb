{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPt2IF3bNw1jBqayz1Y4qWJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kalvelagem/MAT421/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Section 3.2\n",
        "\n",
        "Limits are essential to calculus and mathematical analysis and are used to define contunuity, derivatives, and integrals.  \n",
        "\n",
        "Euclidean norm ||x|| = $\\sqrt{\\sum_{i=1}^d}x_i^2$ for x = $(x_1,...,x_d)^T \\in$ all real numbers\n",
        "\n",
        "Continuous function - a function that does not have any abrupt changes in calye, known as discontinuities.\n",
        "\n",
        "Composition of functions:\n",
        "\n",
        "x -> g -> g(X)\n",
        "\n",
        "g(x) -> f -> f(g(x))\n",
        "\n",
        "x -> f o g (function composition) -> f(g(x))\n",
        "\n",
        "Derivatives:\n",
        "\n",
        "Let f:D -> all real numbers where D subsets all real numbers and let $x_0 \\in$ D be na interior point of D. The derivative of f at $x_0$ is\n",
        "f'($x_0$) = $lim_{h->0} \\frac{f(x_0+h)-f(x_0)}{h}$\n",
        "\n",
        "Let f and g have derivatives at x and let $\\alpha$ and $\\beta$ be constants. The following results hold [alphaf(x) + betag(x)]' = alphaf'(X) + betag'(X)\n",
        "\n",
        "Mean Value Theorem:\n",
        "\n",
        "Let f: [a,b] -> all real numbers be a continuous function and assume that its derivative exists on (a,b). Then there is a < c< b such that f(b) = f(a) + (b-a)f'(c) or put differently $\\frac{f(b)-f(a)}{b-a}$ = f'(c)\n",
        "\n",
        "Jacobian matrix example:\n",
        "\n",
        "f([x]) = [$f_1(x,y)$] = [$x^2y$]\n",
        "\n",
        "  [y]  = [$f_2(x,y)$] = [5x + siny]\n",
        "\n",
        "Jacobian matrix result: \n",
        "\n",
        "$J_f(x,y)$ = [2xy  $x^2$]\n",
        "\n",
        "              [5 cos y]\n",
        "\n",
        "$\\nabla$ f(x) = q\n",
        "\n",
        "Example of a quadratic function: f(x) = 1/2$x^T$Px + $q^T$ + r\n",
        "\n",
        "Gradient of f is $\\nabla$f(x) = 1/2[P + $P^T$]x + q\n",
        "\n",
        "Each component of $\\nabla$f is an affine function of x, so by our previous result the gradient of $\\nabla$f is $H_f = 1/2 [P +P^T]$ \n",
        "\n",
        "Taylor's theorem gives an approximation of a differentiable function around a given point by a polynomial. A power generalization of the Mean Value Theorem that provides polynomial approximations toa function around a point.\n",
        "\n",
        "Example: Let f: D-> all real numbers where D subsets all real numbers. Suppose f has a m times continuous derivative on [a,b]. Then f(b) = f(a) + (b-a)f'(a)+1/2 $(b-a)^2$f''(a) +...+ $\\frac{(b-a)^{m-1}}{(m-1)!}$\n",
        "$f^{m-1}$(a)+$R_m$ where $R_m$ = $\\frac{(b-a)^m}{(m)!}$ $f^{(m)}$(a+Θ(b-a)) for some 0< Θ < 1\n",
        "\n",
        "Example: Consider the function f$(x_1,x_2) = x_1x_2 +x_1^2 + e^{x_1}cosx_2$. wE apply Taylor's Theorem with $x_0$ = (0,0) and x = $(x_1,x_2)$. The gradient is ∇f($x_1,x_2) = (x_2 + 2x_1+e^{x_1}cosx_2,x_1-e^{x_1}sinx_2)^T$\n",
        "\n",
        "The Hessian is \n",
        "$H_f(x_1,x_2) = (2+e^{x_1}cos{x_2}1-e^{x_1}sin{x_2})$\n",
        "\n",
        "$(1-e^{x_1}sinx_2-e^{x_1}cosx_2)$\n",
        "\n",
        "so f(0,0) = 1 and ∇f(0,0) = $(1,0)^T$. Thus the Taylor's Theorem, f($x_1,x_2$) $≈ 1 + $x_1 + 1/2[2x_1^2 + 2x_1x_2+(x_1^2-x_2^2)e^{x_1}cosx_2 - 2x_1x_2e^{x_1}sin(x_2)]$"
      ],
      "metadata": {
        "id": "C1tmyQbaJ1GQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 3.3\n",
        "Let f: all real numbers of d -> all real numbers. the point $x^*$ ∈ all real number of d is a global minimizer of f over all real number of d if f(x) >=  f($x^*$), ∀x \\in all real number of d\n",
        "\n",
        "Local minimizer: let f:all real numbers of d -> all real numbers. The point $x^*$ ∈ all real numbers of d is a local minizer of f over all real numbers of d if there is δ>0 such that f(x) >= f($x^*$), ∀x ∈$B_δ($x^*$)\\{x^*}\n",
        "\n",
        "If the inequality is strict, we say that x* is a strict local minimizer. x* is a local minimizer if there is open ball around x* where it attains the minimum value. \n",
        "\n",
        "Global minimizer - smallest value\n",
        "Local minimizer - local minimial value\n",
        "\n",
        "A real-valued function is called convex if the line segment between any two points on the graph of the function lies above the graph between two points.\n",
        "\n",
        "First-Order Convexity condition: Suppose first that f($z_2$) >= $f(z_1) + ∇f(z_1)^T(z_2-z_1)$ for all $z_1,z_2$. For any x,y, and α ∈ [0,1], let w= (1-α)x+αy.\n",
        "\n",
        " Then taking $z_1 =w$ and $z_2 = x$ gives f(x)>= f(w) + ∇$f(W)^T$ (x-w) and taking $z_1$ = w and $z_2$ =y gives f(y) >= f(w) + ∇$f(w)^T$(y-w). \n",
        "\n",
        "Multiplying the first inequality by (1-α) and the second one by α and adding them up gives (1-α)f(x) + αf(y) >= f(w) + ∇$f(w)^T$ ([{1-α)x+αy]-w) = f(w)\n",
        "\n",
        "For the other direction, assume that f is convex. For any x,y and α ∈ (0,1), by the Multivariate Mean Value Theorem, for some ξ ∈ (0,1) it holds that f(w) = f(x+α(y-x)) = f(x) + α$(y-x)^T$ ∇f(x+ξα(y-x)), while convexity implies f(w)<=(1-α)f(x)+αf(y). Combining, rearranging and dividing by α gives $(y-x)^T∇f(x+ξα(y-x))<=f(y)-f(x)\n",
        "\n",
        "For a convex function, sufficient (and therefore necessary) condition for minimizers is ∇$f(x_0)$ = 0.\n",
        "\n",
        "Global Minimizer of Convex Functions: Let f: all real numbers of d -> all real numbers be a convex function. By contradiction, suppose $x_0$ is a local minimizer, but not a global minimizer. Then there is y such that f(y) < $f(x_0)$\n",
        "\n",
        "Global minimizer x* = -Q$Λ^{-1}$$Q^T$1\n",
        "\n",
        "Gradient descent is an iterative optimization algorithm for finding a local minimum of a differentiable function. Letf: all real numbers of d -> all real number is continuously differentiable. We restrict ourselves to unconstrained minimization problems of the form $min_{x∈all real numbers of d}$ f(x), a less naive approach might be to find all stationary points of f, that is, those x's such that ∇f(x) = 0. Adn then choose that x among them that produces the smallest value of f(x)\n",
        "\n",
        "Example: Consider the least-squares problem $min_{x∈all real numbers of d}$ $||Ax-b||^2$\n",
        "where A ∈ $ all real numbers^{nxd}$ has full column rank. In particular d<=n. The objective function is a quadratic function f(x) = $||Ax-b||^2$ = $(Ax-b)^T$(Ax-b) = $x^TA^TAx-2b^TAx+b^Tb$\n",
        "\n",
        "So the stationary points satisfy $A^TAx = A^Tb$ which you may recognize as the normal equation for the least squares problem. The Hessian of f is $H_f(x) = 2A^TA$\n",
        "\n",
        "The steepest descent approach is to find smaller values of f by successively following directions in which f decreases. as we have seen in the proof of the First-Order Necessary Condition, -∇f provides such a direction.\n",
        "\n",
        "Let f: all real number of d -> all real numbers be continously differentiable at $x_0$. For any unit vector v ∈ all real numbers of d, $\\frac{df(x_0)}{dv}$ >= $\\frac{df(x_0)}{dv*}$ where v* = $\\frac{∇f(x_0)}{||∇f(x_0)||}$\n",
        "\n",
        "The step size is chosen to minimize $α_k$ = arg $min_{a>0}f(x^k-α∇f(x^k))$. The steepest desscent started frmo any $x^0$ produces a sequence $x^k$, k = 1,2,... such that if ∇f($x^k$) is not equal to 0 then $f(x^{k+1}) <= f(x^k)$ ∀k>=1"
      ],
      "metadata": {
        "id": "pKOGgSz7eEmh"
      }
    }
  ]
}